---
title: "02_bashing_data"
date: "8/30/2022"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Let's start with some of the very basics of BASH to get everybody on the same page:
 
cd - to change directories
ls - list the files
pwd - tells you the pathway you are currently at (very useful actually!)

```{BASH}

cd /scratch/Shares/rinnclass/CLASS_2022/
ls
pwd

# Wait could there be more? let's try:

ls -lah
```
-l for long
-a for all
-h human readable
Basically I typically always use these flags


let's create your directory

```{BASH}

mkdir NAME_of_dir

cd NAME_of_dir

# This is where we will be working all of class !
```

Every function has a manual entry (man)
```{BASH}

man mkdir
# Press q to escape

```


Now let's make a new file using touch
```{Bash}

touch test.txt
ls

```
woah a new file shows up! What is in it? lets use Nano

```{Bash}

nano test.txt
# type whatever
# ctrl + x, Y for yes -- then enter -- to exit nano

```

Now let's take a look at the file with cat

```{Bash}
cat test.txt

# here are the top 10 lines

head -10 test.txt

# bottom lines

tail -10 test.txt
```


Let's make another file and combine two files to highlight other functionality of the cat command
First let's remove (using rm command) the test.txt file and make a new one.

```{BASH}

rm test.txt
touch test.txt
nano test.txt
"add whatever text"

```
Now we will make a second file and merge the two files into one file with cat.

```{BASH}



nano test2.txt
# type whatever
cat test.txt test2.txt > test3.txt
cat test3.txt

```

let's move the files

```{Bash}

mkdir practice

mv test2.txt practice
mv test3.txt practice
mv test.txt practice
ls

# If we want to copy it we can use cp

cp test2.txt /practice

# note simply changes file path and cp recreates the entire directory.

```

Nice and tidy. However that could be quite laborious if you wanted to move a bunch of files. So we can use WILDCARDS


http://www.linfo.org/wildcard.html

```{BASH}

mv *.txt practice
ls

```
This will move any file that ends in .txt the star means anything counts.

Now let's say you want to move the files back to the orignal directory:

```{BASH}

cd practice
mv *.txt ../
```

The ../ means one directory up from the current path. If oyu want to go up two 
directories you can just add more ../../ etc...

__________________________________
Imagine how much time one uses typing long file paths in the terminal. For example, in this class we will be using:

/Shares/rinn_class/data/CLASS_2021

That is no fun to type every time and then go to the directory of interest. 

Good news there is a solution (used by nextflow and just how useful later) its called a sym-link and you have probably used them before. 

Let's make a sym-link to the class folder in your home directory 

```{BASH}

cd ~/
# or some directoy you use a lot on your local computer

  
ln -s /scratch/Shares/rinnclass/CLASS_2022/<identikey> CLASS 
ls

```

Now you see a simlink called CLASS. You just cd CLASS and voila you are in class :)

Another handy short cut is to see how big a folder is. Often you are downloading to
or working on a folder and need to see if it became bigger or smaller. This is best
done wtih disk usage (du)

```{BASH}

cd ~/
du -sh ~/
  
```

The -sh flag is for "s"ummary and "h"uman readable


|||||||||||||||||||||||||||||||||
The pipe
|||||||||||||||||||||||||||||||||


The pipe and xargs are two of the most elegant aspects of BASH. Let's try something
simple, so simple it may end up being used quite often :)

Many times a folder you are indexing may have hundreds or thousands of files.
There is no way we want to count them manually. So we can use the pipe to list (ls) 
the files in a directory and pipe it to word count (wc) to count the number of files.

Let's see:

```{BASH}

cd ~/
ls | wc -l

```
Here the list output becomes the standard input to the word count owing to the pipe.
Or the pipe passed along the standard output of ls to standard input of wc. The 
-l flag is for the line count. 


||||||||||||||||||||||||||||||||||||||||||||||||
General Regularized Expression Print (GREP)
||||||||||||||||||||||||||||||||||||||||||||||||

Some fun background reading of the story behind GREP:
https://www.quora.com/Where-did-GREP-come-from

It's like the search bar, before there was a search bar. Grep will go look for
the search key in a file. If there is a match then you can return just about anything
in the file. If you have ever done Vlookup in Xcel it maybe familiar in that sense. 
But the reality it is so simple, elegnat and powerful we will use GREP a lot in class.


Let's download and play with the encode .TSV file. This is a file of ENCODE data 
we will learn more about soon. 
For now just think of it as a file

```{BASH}

[Download here](https://www.dropbox.com/s/ij798is442fyt3h/encode_awk_lessons.tsv)

# wget URL to download (make sure you know which directory you are in etc)

wget https://www.dropbox.com/s/ij798is442fyt3h/encode_awk_lessons.tsv



```

Now let's take a look at the file with 'cat' 
```{BASH}

cat encode_awk_lessons.tsv

```

Cat will print all items in a file and sometimes they are very long. So there are other unix commands to get the head and tail of a file while specificying how many lines you want:

```{BASH}

head -1 encode_awk_lessons.tsv
tail -1 encode_awk_lessons.tsv

```

Yikes ok, so you see all the "/" that means it is tab deliminated. We would see
commas if it was a .csv.

So this is not very readable. Let's use GREP to get what we want. Let's say we are 
interested in all the samples that start with POL for POL II or POLR2A, there are 
many ways to spell but we can search for anything that starts with POL.

```{BASH}

grep -ia 'pol' encode_awk_lessons.tsv | wc -l

```
I guess we see that there are 11 entries for anything matching the text of pol.
We used the -i flag which is very useful to match any type of the same letters.

People spell gene names all kinds of different ways (with and with out capitals etc).
So the -i will match Pol POl and POL as well as poL. 

# Try running with out the -i (no matches!).

Note that we piped to wc -l, if you take that out what happens?

# Now open up the same file in XCEL and search for pol -- do you find 11 enteries?

So grep likes to go look but needs to be told where to disseminate what was found!
So let's print the grep standard output to a file using ' > ' 
'>' is a very powerful "pipe" if you will to say "take standard out to print"

Let's take a look at these 11 matches.

```{BASH}

grep -i 'pol' encode_awk_lessons.tsv > grep_out.txt
ls
wc -l grep_out.txt
cat grep_out.txt

```

So we see a new file was printed, but let's open in xcel for ease.

Ok, so this is a great example of how to be careful with grep. We loosened the 
search a bit too much and it turns out some of those weird encode acessions had pol 
in the string (e.g., ENCFF744POL)! But we do see the samples we want are "POLR2A" -- let's revamp our
grep.

```{GREP}

grep -w 'POLR2A' encode_awk_lessons.tsv > grep_out.txt
cat grep_out.txt

```
Here the -w requires an exact match of the whole word.
Now we see a file with just the POLR2A experiments -- as we wanted.

Let's say we wanted to know how many unique DBPs we are about to study. We can
bring AWK in, which is like selecting and moving columns in excel. So we could awk
the column with DBP names and put it into "unique" to know the number of unique DBPS.


|||||||||||||||||||||||||||||||||||||||||||||||||||||||
Alfred Aho peter Weinberger brian Kernighan = AWK
|||||||||||||||||||||||||||||||||||||||||||||||||||||||

So we can use AWK in a similar way to grep to get started:

```{BASH}

man awk
awk -F $'\t' '{if ($6 == "POLR2A") print $0;}' encode_awk_lessons.tsv | wc -l 

```

The syntax for awk is:
awk -options 'selection _criteria {action }' input-file > output-file
*The options here is -F (for field separator in file being operated on)
*the $'\t' says the file is a tab separated file. the "$" is to set the variable tab separated('\t')


This awk command performs: the selection criteria is an if statement that if column 6 ($6)
is equal to (exactly ==) the "POLR2A" term. print $0 means to print the lines that
match these arguments and ; means end. Then, somewhat counter intuitive we put the
file we want to operate on and then > output file. 


# Let's now use awk to acomplish the goal of seeing how many unique DBPs are in this file.

First let's make a file with just the names of DBPs.
* note there are many ways to do the same thing in awk.
* discuss what this syntax is:

```{BASH}

awk 'BEGIN {FS="\t"}; {print $6}' encode_awk_lessons.tsv > DBP.txt
cat DBP.txt

? How many DBPs are we going to study?
  
```

The statement above is using the function print to "print" the column of choice.
In this case we are choosing column 6 as it has the names of all the DBPs.

The final argument after the awk instructions is the file in which to perform the
awk instructions on -- 'encode_awk_lessons.tsv'

Cool, but it's all in standard output right now -- let's get back to the quesiton:

# How many unique DBPs could we analyze?

To do so we will just take advantage of the pipe and sort command.
```{BASH}
man sort
```
Let's put it together:

```
awk 'BEGIN {FS="\t"}; {print $6}' encode_awk_lessons.tsv | sort -u | wc -l
```
We piped out the awk arguments from standard in put to standard output of sort.
We used the -u flag to sort and then collapse the sort to unique string names.
then we simply count the lines to see if it worked?

# How many?? And why could this number be less ??

Let's print this out to a file:

```{BASH}

awk 'BEGIN {FS="\t"}; {print $6}' encode_awk_lessons.tsv > dbp.tsv

```


->O<-->O<-->O<-->O<-->O<-->O<-->O<-->O<-
for loops in BASH
->O<-->O<-->O<-->O<-->O<-->O<-->O<-->O<-


# Syntax for all for loops in bash: For x (in) ; do ; done


```{BASH}

for x in $(seq 1 42); do echo bash is cool $x; done

```



# Let's start with an example to understand how the computer thinks about this:


```{BASH}

for x in 1 1 1 1
do 
echo BCHM5631 
done

# or
for x in 1 1 1 1; do echo BCHM5631; done

```


What we get out is 4 prints of BCHM5631 -- 

# what happens if we change the numbers?

```{BASh}

for x in 1 3 11 14
do 
echo BCHM5631 $x
done

# or
for x in 1 3 11 14; do echo BCHM5631 $x; done

# Notice the added "$x" this means it will print the value it's "in" currently.

```

Same result, you could even change it to apple, banana or anything -- the number
of objects after "in" are the inputs for each loop until there is nothing more to 
be "in". 

# Lets try a nested for loop

```{BASH}

for x in $(seq 1 5)
do 
for y in A B C
do
echo "$x:$y"
done
done
** try copy and pasting the above into terminal 

# or 
for x in $(seq 1 5); do for y in A B C; do echo "$x:$y"; done ; done

```

Let's try this one:

```{BASH}

for x in $(seq 1 42)
do 
echo BCHM5631
done

# or
for x in $(seq 1 42); do echo BCHM5631; done

```


We would probably rather do a for loop while reading in a file and changing something.

# Let's change the text in our encode practice file. 

```{BASH}

for line in $(cat encode_awk_lessons.tsv)
do 
echo "$line"
done

# or

for line in $(cat encode_awk_lessons.tsv); do echo "$line"; done

# Woah in the blink of an eye we just used cat to print each line of the file :)
# We basically just did cat but used a for loop to print one line at a time.

```

Typically we would want to maniputate or change the name of a column in a file
systematically with "sed". Sed is a simple elegant and powerful unix commnad that
can parse and transform text. 

```{BASH}

man sed

# This basically distills down to 

sed -i 's/old-word/new-word/g' *.txt 
the s/ is a substitute command 

```



# Let's try changing POLR2A to POL2

```{BASh}

sed -i 's/POLR2A/POL2/g' encode_awk_lessons.tsv

# Note you have changed the file forever -- there is no undo in bash 

```

# Did you see a change? 
# How would you check?

sed is a really nice way to change chromosome annotations that tend to change in time
for example chromosome 1 maybe chr1 C1 or 1 -- in one file and a different spelling
in another but if they ever need to connect you will want them in the same format.


# Let's try sed in a for loop to change

```{BASH}

for f in $(cat encode_awk_lessons.tsv)
do
sed -i 's/USF2/USA/g' encode_awk_lessons.tsv
echo "$f"
done

# or

for f in $(cat encode_awk_lessons.tsv); do sed -i 's/USF2/USA/g' encode_awk_lessons.tsv; echo "$f"; done

```

This is a very silly for loop because sed already kinda has it built in...sed is just 
like find and replace. 


*********************
EXCERCISE
*********************

Use what you learned above to make a .tsv file of the Experiment ID, Accession ID and Target DNA binding protein being (hint it maybe easiest to find the header information first)


_________________________ Bonus Bash Fun _________________________ 


### Bonus. Have you ever had a folder of folders of folders? This is often the case
with photo libraries, music and other large archives. But let's say you simply just
want to retreive all the photos on an app before the app goes extinct etc. 

You can do this very easily with BASH alone: with the powerful find command:

```{BASH}

# check what find does
man find

# use find to dig out all the .jpg from directories of directories

find . -type f -name '*.jpg' -exec mv -i {} ../compiled/ \;

```

with this snippet we call find to look in the directory we are in (. = here)
we used the -type flag to look for files with -name that is anything that ends in
.jpg ('*.jpg'). Then the cool stuff starts happening. We call -exec for execute the 
next command. In otherwords standard out put is going to be "piped" into the move
command (mv). So we floated all the file paths ending in .jpg to the mv funciton and
last we just tell the computer where to move the files (or copy (cp)). The back slash
semi-colon ends the bash script. Not so bad -- just standard input and output movements.






